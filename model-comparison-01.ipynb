{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukilau/anaconda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "This data set contains 2001 observations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define function for text preprocessing\n",
    "def text_cleaning(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()  # remove html tag\n",
    "    text = re.sub(r'\\@\\w+',\"\", text)  # remove @tag \n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)  # letters only\n",
    "    return text\n",
    "\n",
    "def text_preprocess(X):\n",
    "    clean_X = [] \n",
    "    for ind, val in X.iteritems():\n",
    "        clean_text = text_cleaning(val)\n",
    "        clean_X.append(clean_text)\n",
    "    return clean_X\n",
    "\n",
    "\n",
    "# load data\n",
    "print(\"Loading data ...\")\n",
    "df = pd.read_csv(\"sentiment.tsv\", header=None, names=[\"sentiment\",\"tweet\"], delimiter=\"\\t\", quoting=2)\n",
    "print(\"This data set contains %d observations\" % df.shape[0])\n",
    "print()\n",
    "\n",
    "X = df[\"tweet\"]\n",
    "y = df[\"sentiment\"]\n",
    "y = preprocessing.LabelBinarizer().fit_transform(y)\n",
    "c, r = y.shape\n",
    "yvec = y.reshape(c,)\n",
    "\n",
    "\n",
    "# text preprocessing\n",
    "X_clean = text_preprocess(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** VADER + SVC ******\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set :\n",
      "{'C': 0.1, 'kernel': 'poly'}\n",
      "Best score: 0.747\n",
      "Grid scores :\n",
      "0.745 (+/-0.072) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.076) for {'C': 0.1, 'kernel': 'poly'}\n",
      "0.745 (+/-0.075) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.738 (+/-0.068) for {'C': 0.1, 'kernel': 'sigmoid'}\n",
      "0.716 (+/-0.093) for {'C': 0.5, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.075) for {'C': 0.5, 'kernel': 'poly'}\n",
      "0.676 (+/-0.131) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.744 (+/-0.075) for {'C': 0.5, 'kernel': 'sigmoid'}\n",
      "0.731 (+/-0.077) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.075) for {'C': 1, 'kernel': 'poly'}\n",
      "0.663 (+/-0.099) for {'C': 1, 'kernel': 'linear'}\n",
      "0.743 (+/-0.077) for {'C': 1, 'kernel': 'sigmoid'}\n",
      "0.724 (+/-0.063) for {'C': 3, 'kernel': 'rbf'}\n",
      "0.742 (+/-0.072) for {'C': 3, 'kernel': 'poly'}\n",
      "0.671 (+/-0.128) for {'C': 3, 'kernel': 'linear'}\n",
      "0.742 (+/-0.077) for {'C': 3, 'kernel': 'sigmoid'}\n",
      "0.725 (+/-0.067) for {'C': 5, 'kernel': 'rbf'}\n",
      "0.736 (+/-0.073) for {'C': 5, 'kernel': 'poly'}\n",
      "0.681 (+/-0.131) for {'C': 5, 'kernel': 'linear'}\n",
      "0.739 (+/-0.085) for {'C': 5, 'kernel': 'sigmoid'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   17.3s finished\n"
     ]
    }
   ],
   "source": [
    "# VADER + SVC \n",
    "\n",
    "# compute polarity score using VADER\n",
    "print(\"****** VADER + SVC ******\")\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "def vader_polarity(text):\n",
    "    score = vader.polarity_scores(text)\n",
    "    feature_vec =[]\n",
    "    feature_vec.append(score[\"neg\"])\n",
    "    feature_vec.append(score[\"neu\"])\n",
    "    feature_vec.append(score[\"pos\"])\n",
    "    feature_vec = np.array(feature_vec)\n",
    "    return feature_vec\n",
    "Xvec = [vader_polarity(text) for text in X]\n",
    "\n",
    "\n",
    "# Grid search on SVC\n",
    "parameters = {\"C\" : [0.1,0.5,1,3,5], \"kernel\":[\"rbf\",\"poly\",\"linear\", \"sigmoid\"]}   \n",
    "grid_search = GridSearchCV(SVC(), parameters, cv=10, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(Xvec, yvec)\n",
    "print(\"Best parameters set :\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Grid scores :\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** CountVectorizer + MultinomialNB ******\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set :\n",
      "{'clf__alpha': 3, 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.766\n",
      "Grid scores :\n",
      "0.731 (+/-0.088) for {'clf__alpha': 0.1, 'vect__ngram_range': (1, 1)}\n",
      "0.721 (+/-0.073) for {'clf__alpha': 0.1, 'vect__ngram_range': (1, 2)}\n",
      "0.762 (+/-0.073) for {'clf__alpha': 1, 'vect__ngram_range': (1, 1)}\n",
      "0.754 (+/-0.067) for {'clf__alpha': 1, 'vect__ngram_range': (1, 2)}\n",
      "0.766 (+/-0.071) for {'clf__alpha': 3, 'vect__ngram_range': (1, 1)}\n",
      "0.761 (+/-0.068) for {'clf__alpha': 3, 'vect__ngram_range': (1, 2)}\n",
      "0.760 (+/-0.069) for {'clf__alpha': 10, 'vect__ngram_range': (1, 1)}\n",
      "0.756 (+/-0.071) for {'clf__alpha': 10, 'vect__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    6.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Grid search on CountVectorizer + MultinomialNB\n",
    "\n",
    "print(\"****** CountVectorizer + MultinomialNB ******\")\n",
    "clf = Pipeline([(\"vect\", CountVectorizer()),(\"clf\", MultinomialNB())])\n",
    "parameters = {\"vect__ngram_range\" : ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "#     \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "#     \"vect__max_features\": (None, 1000, 4000),\n",
    "#     \"vect__stop_words\" : (None, \"english\"),\n",
    "        \"clf__alpha\" : [0.1,1,3,10]\n",
    "             }\n",
    "grid_search = GridSearchCV(clf, parameters, cv=10, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_clean, yvec)\n",
    "print(\"Best parameters set :\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Grid scores :\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** CountVectorizer + TfidfTransformer + MultinomialNB ******\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set :\n",
      "{'clf__alpha': 3, 'vect__ngram_range': (1, 1)}\n",
      "Best score: 0.779\n",
      "Grid scores :\n",
      "0.742 (+/-0.083) for {'clf__alpha': 0.1, 'vect__ngram_range': (1, 1)}\n",
      "0.741 (+/-0.073) for {'clf__alpha': 0.1, 'vect__ngram_range': (1, 2)}\n",
      "0.775 (+/-0.063) for {'clf__alpha': 1, 'vect__ngram_range': (1, 1)}\n",
      "0.772 (+/-0.062) for {'clf__alpha': 1, 'vect__ngram_range': (1, 2)}\n",
      "0.779 (+/-0.057) for {'clf__alpha': 3, 'vect__ngram_range': (1, 1)}\n",
      "0.776 (+/-0.055) for {'clf__alpha': 3, 'vect__ngram_range': (1, 2)}\n",
      "0.776 (+/-0.052) for {'clf__alpha': 10, 'vect__ngram_range': (1, 1)}\n",
      "0.771 (+/-0.051) for {'clf__alpha': 10, 'vect__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    6.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Grid search on CountVectorizer + TfidfTransformer + MultinomialNB\n",
    "\n",
    "print(\"****** CountVectorizer + TfidfTransformer + MultinomialNB ******\")\n",
    "clf = Pipeline([(\"vect\", CountVectorizer()),('tfidf', TfidfTransformer()), (\"clf\", MultinomialNB())])  \n",
    "parameters = {\"vect__ngram_range\" : ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "#     \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "#     \"vect__max_features\": (None, 1000, 4000),\n",
    "#     \"vect__stop_words\" : (None, \"english\"),\n",
    "        \"clf__alpha\" : [0.1,1,3,10]\n",
    "             }\n",
    "grid_search = GridSearchCV(clf, parameters, cv=10, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_clean, yvec)\n",
    "print(\"Best parameters set :\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Grid scores :\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
